{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:17.777553Z",
     "start_time": "2024-11-12T17:51:17.774939Z"
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adam Candr치k/M치ria Matu코iskov치 - 50%/50%\n",
    "\n",
    "# Imports"
   ],
   "id": "6a0c4b3dbec7aea8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:17.821374Z",
     "start_time": "2024-11-12T17:51:17.816970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler"
   ],
   "id": "2f60aea49ced7511",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Global variables",
   "id": "1998a609549d5b4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:17.902288Z",
     "start_time": "2024-11-12T17:51:17.899072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_column = 'mwra'\n",
    "test_size = 0.3\n",
    "random_state = 42"
   ],
   "id": "567d453fc4875c92",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.039280Z",
     "start_time": "2024-11-12T17:51:17.976695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "connections_file = \"../data/Connections.csv\"\n",
    "processes_file = \"../data/Processes.csv\"\n",
    "\n",
    "connections = pd.read_csv(connections_file, sep='\\t')\n",
    "processes = pd.read_csv(processes_file, sep='\\t')"
   ],
   "id": "9858ba9492149dc2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change the names of the columns",
   "id": "40fd4288cc2cb06c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.123530Z",
     "start_time": "2024-11-12T17:51:18.115368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c_connections = connections.rename(columns={\n",
    "    \"c.katana\": \"facebook\",\n",
    "    \"c.android.chrome\": \"chrome\",\n",
    "    \"c.android.gm\": \"gmail\",\n",
    "    \"c.dogalize\": \"dogalize\",\n",
    "    \"c.android.youtube\": \"youtube\",\n",
    "    \"c.updateassist\": \"updateassist\",\n",
    "    \"c.UCMobile.intl\": \"UCMobile.intl\",\n",
    "    \"c.raider\": \"raider\",\n",
    "    \"c.android.vending\": \"vending\",\n",
    "    \"c.UCMobile.x86\": \"UCMobile.x86\",\n",
    "})\n",
    "\n",
    "p_processes = processes.rename(columns={\n",
    "    \"p.katana\": \"facebook\",\n",
    "    \"p.android.chrome\": \"chrome\",\n",
    "    \"p.android.gm\": \"gmail\",\n",
    "    \"p.dogalize\": \"dogalize\",\n",
    "    \"p.android.vending\": \"vending\",\n",
    "    \"p.android.packageinstaller\": \"packageinstaller\",\n",
    "    \"p.system\": \"system\",\n",
    "    \"p.android.documentsui\": \"documentsui\",\n",
    "    \"p.android.settings\": \"settings\",\n",
    "    \"p.android.externalstorage\": \"externalstorage\",\n",
    "    \"p.android.defcontainer\": \"defcontainer\",\n",
    "    \"p.inputmethod.latin\": \"inputmethod.latin\",\n",
    "    \"p.process.gapps\": \"gapps\",\n",
    "    \"p.simulator\": \"simulator\",\n",
    "    \"p.android.gms\": \"google mobile services (gms)\",\n",
    "    \"p.google\": \"google\",\n",
    "    \"p.olauncher\": \"olauncher\",\n",
    "    \"p.browser.provider\": \"browser provider\",\n",
    "    \"p.notifier\": \"notifier\",\n",
    "    \"p.gms.persistent\": \"gms.persistent\",\n",
    "})"
   ],
   "id": "205a7ec9b037694e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change the type of timestamp to int64 of connections' dataset:",
   "id": "cc7f6c10df095365"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.217460Z",
     "start_time": "2024-11-12T17:51:18.205498Z"
    }
   },
   "cell_type": "code",
   "source": "c_connections['ts'] = pd.to_datetime(c_connections['ts']).astype(np.int64)",
   "id": "fb43e5d9a706829c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change the type of timestamp to int64 of processes dataset:",
   "id": "6545626e46e2f337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.305400Z",
     "start_time": "2024-11-12T17:51:18.293251Z"
    }
   },
   "cell_type": "code",
   "source": "p_processes['ts'] = pd.to_datetime(p_processes['ts']).astype(np.int64)",
   "id": "5df685fd7ce5e116",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge datasets connections and processes:",
   "id": "5aeeb7a76d1b7869"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.396089Z",
     "start_time": "2024-11-12T17:51:18.383730Z"
    }
   },
   "cell_type": "code",
   "source": "merged_dataset = pd.merge(c_connections, p_processes, on=['imei', 'ts', 'mwra'])",
   "id": "2f3e604e1124eeda",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check for missing values and duplicities",
   "id": "47a9245e170824a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.482809Z",
     "start_time": "2024-11-12T17:51:18.478397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "has_nan = merged_dataset.isnull().values.any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The dataset has NaN values.\")\n",
    "else:\n",
    "    print(\"No NaN values found in the dataset.\")"
   ],
   "id": "27c5c67ef7aa8630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in the dataset.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.630404Z",
     "start_time": "2024-11-12T17:51:18.583670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "has_duplicity = merged_dataset.duplicated().any()\n",
    "\n",
    "if has_duplicity:\n",
    "    print(\"The dataset has duplicity values.\")\n",
    "    merged_dataset.drop_duplicates(inplace=True)\n",
    "else:\n",
    "    print(\"No duplicity values found in the dataset.\")"
   ],
   "id": "4d5bee41d489feb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has duplicity values.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Drop values which are not helpful for further training:",
   "id": "aad82bb1d1535bbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.729590Z",
     "start_time": "2024-11-12T17:51:18.721906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_dataset.drop('ts', axis=1, inplace=True)\n",
    "merged_dataset.drop('imei', axis=1, inplace=True)"
   ],
   "id": "1d2453648d239eca",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outlier deletion",
   "id": "f4aff6ddb09bb591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.910251Z",
     "start_time": "2024-11-12T17:51:18.883012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Source: https://www.kaggle.com/code/marcinrutecki/outlier-detection-methods\n",
    "\n",
    "def StandardDevDetection(data, n, columns):\n",
    "\n",
    "    outliers_inx = []\n",
    "    lower = 0\n",
    "    upper = 0\n",
    "\n",
    "    for column in columns:\n",
    "        # Calculate mean and standard derivation of each column\n",
    "        data_mean, data_std = mean(data[column], axis=0), std(data[column], axis=0)\n",
    "        # print('column=', column, 'len=', len(data), 'mean=', data_mean, 'std=', data_std)\n",
    "\n",
    "        # Divide it to the three outliers in the standard deviations:\n",
    "        cut_off = data_std * 3\n",
    "        lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "        # print('column=', column, 'cutoff=', cut_off, 'lower=', lower, 'upper=', upper)\n",
    "\n",
    "        # Filter the dataframe:\n",
    "        outliers = data[(data[column] < lower) | (data[column] > upper)].index\n",
    "        # print('Identified outliers:', len(outliers))\n",
    "\n",
    "        outliers_inx.extend(outliers)\n",
    "\n",
    "    outliers_inx = Counter(outliers_inx)\n",
    "    multiple_outliers = list( k for k, v in outliers_inx.items() if v > n )\n",
    "\n",
    "    data_uppper = data[data[column] > upper]\n",
    "    data_lower = data[data[column] < lower]\n",
    "    # print('Total number of outliers is:', data_uppper.shape[0] + data_lower.shape[0])\n",
    "\n",
    "    return multiple_outliers\n",
    "\n",
    "\n",
    "columns = merged_dataset.columns\n",
    "result = StandardDevDetection(merged_dataset, 1, columns)\n",
    "\n",
    "new_dataset = merged_dataset.drop(result, axis = 0).reset_index(drop=True)"
   ],
   "id": "50efea450112a31d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data splitting",
   "id": "fb210303553d1b18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:18.925842Z",
     "start_time": "2024-11-12T17:51:18.914265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "mwra = new_dataset[target_column]\n",
    "\n",
    "data = new_dataset.drop(columns=[target_column], axis=1)\n",
    "\n",
    "train_data, test_data, train_mwra, test_mwra = train_test_split(data, mwra, test_size=test_size, random_state=random_state)"
   ],
   "id": "dff920d0100bc43",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:19.012519Z",
     "start_time": "2024-11-12T17:51:19.005909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# features selected from our previous analysis\n",
    "selected_features = ['gmail_x', 'gapps', 'facebook_x', 'chrome_x', 'vending_x',\n",
    "                     'youtube', 'dogalize_x', 'updateassist', 'UCMobile.intl']\n",
    "\n",
    "# global variable to store the preprocessor so we can use it later\n",
    "preprocessor = None\n",
    "\n",
    "# this class was created with help from Claude.ai\n",
    "# we were unsure of how to work with pipeline\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.pipeline = None\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        numeric_pipeline = Pipeline([\n",
    "            ('standard_scaler', StandardScaler()),\n",
    "            ('power_transform', PowerTransformer(method='yeo-johnson')),\n",
    "            ('minmax_scaler', MinMaxScaler()),\n",
    "            ('feature_select', SelectKBest(score_func=f_classif, k=len(selected_features)))\n",
    "        ])\n",
    "\n",
    "        self.pipeline = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numeric', numeric_pipeline, selected_features)\n",
    "            ],\n",
    "            remainder='drop'  # drop any columns not specified in the transformers\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        if self.pipeline is None:\n",
    "            self.create_pipeline()\n",
    "        return self.pipeline.fit_transform(X, y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Pipeline has not been fitted yet. Call fit_transform first.\")\n",
    "        return self.pipeline.transform(X)\n",
    "\n",
    "def process_data(train_data, test_data, train_mwra=None):\n",
    "    global preprocessor\n",
    "    preprocessor = DataPreprocessor()\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(train_data, train_mwra)\n",
    "    X_test_processed = preprocessor.transform(test_data)\n",
    "\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "def process_with_preprocessor(preprocessor, data):\n",
    "    return preprocessor.transform(data)"
   ],
   "id": "f96da14071589eda",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:19.289006Z",
     "start_time": "2024-11-12T17:51:19.089175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_processed, X_test_processed = process_data(train_data, test_data, train_mwra)\n",
    "\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed,  columns=selected_features)\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed,  columns=selected_features)\n",
    "\n",
    "X_train_processed_df.to_csv('dataset_df_train.csv', index=False)\n",
    "X_test_processed_df.to_csv('dataset_df_test.csv', index=False)\n",
    "\n",
    "# create dataframes for the target column (aka label)\n",
    "y_train_df = pd.DataFrame(train_mwra, columns=[target_column])\n",
    "y_test_df = pd.DataFrame(test_mwra, columns=[target_column])\n",
    "\n",
    "print(\"Processed training data shape:\", X_train_processed_df.shape)\n",
    "print(\"Processed test data shape:\", X_test_processed_df.shape)"
   ],
   "id": "148bb3ca062331a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training data shape: (10402, 9)\n",
      "Processed test data shape: (4458, 9)\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
